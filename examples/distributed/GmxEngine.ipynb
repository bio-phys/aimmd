{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gromacs engines\n",
    "This notebook showcases the use of the pyhton classes used to steer gromacs from python. It will only work if the gromacs executables are available (e.g. in your `$PATH` variable).\n",
    "\n",
    "There are two main classes you will use together:\n",
    " - `aimmd.distributed.MDP`, a python class which parses a gromacs molecular dynamics parameter file (`.mdp`) and makes its content available via a dictionary-like interface\n",
    " - the `aimmd.distributed.GmxEngine` or the `aimmd.distributed.SlurmGmxEngine`, both share a common interface and are `aysnc/await` enabled python wrappers to run gromacs locally or via the SLURM workload manager, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and some basic checks that everything is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if using the module system to make gromacs and friends available:\n",
    "# check that they are loaded!\n",
    "#module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/gromacs-2020.4/bin/gmx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# unix only, check that gmx is available\n",
    "which gmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import MDAnalysis as mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import aimmd\n",
    "import aimmd.distributed as aimmdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup working directory and the number of gromacs simulations to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_engines = 4\n",
    "\n",
    "#scratch_dir = \".\"\n",
    "#scratch_dir = \"/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/\"\n",
    "scratch_dir = \"/home/think/scratch/aimmd_distributed/\"\n",
    "wdirs = [os.path.join(scratch_dir, f\"engine_wdir{i}\") for i in range(n_engines)]\n",
    "\n",
    "for d in wdirs:\n",
    "    if not os.path.isdir(d):\n",
    "        os.mkdir(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `aimmd.distributed.GmxEngine` (and `aimmd.distributed.SlurmGmxEngine`)\n",
    "Both provide the functionality of the gromacs grompp and mdrun executables in one class, i.e. given molecular dynamics parameters and possibly an initial configuration they will setup and steer a MD run. Their interfaces differ only in the additional `sbatch_script` that the slurm engine requires at initialization time. Both engines need the gromacs exetucables to be available, specifically `gmx grompp` and `gmx mdrun`  (`gmx_mpi mdrun` for the `SlurmGmxEngine`). The `SlurmGmxEngine` naturally also must have access to the slurm executables, specifically `sbatch`, `sacct` and `scancel`. However all of these can be set either at initialization time via keyword arguments or globally as attributes to the uninitialized class.\n",
    "\n",
    "Each engine has a `prepare()` method (which will call `grompp`) and multiple methods to then run the simulation, namely `run()`, `run_walltime()` and `run_nsteps()`. The additional `prepare_from_files()` method can be used to continue a previous MD run from given `deffnm` and `workdir` (assuming all files/parts are there), note that it will (currently) not call `grompp` again and therefore assumes that the portable run input file (`.tpr`) allows for the continuation (i.e. has no or a sufficiently large integration step limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a list of identical engines to showcase the power of concurrent execution :)\n",
    "engines = [aimmdd.GmxEngine(gro_file=\"gmx_infiles/conf.gro\",  # required\n",
    "                            top_file=\"gmx_infiles/topol.top\",  # required\n",
    "                            ndx_file=\"gmx_infiles/index.ndx\",  # optional (can be omited or None), however naturally without an index file\n",
    "                                                               # you can not reference custom groups in the .mdp-file or MDP object \n",
    "                            # limit each engine to 2 threads (the box is so small that otherwise the domain decomposition fails)\n",
    "                            mdrun_extra_args=\"-nt 2\",  # use this if your version of GMX is compiled with thread-MPI support\n",
    "                            #mdrun_extra_args=\"-ntomp 2\",  # use this for GMX without thread-MPI support\n",
    "                            )\n",
    "           for _ in range(n_engines)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `aimmd.distributed.MDP`\n",
    "The `MDP` is a dictionary-like interface to a parsed gromacs molecular dynamics parameter file `.mdp` file to enable easy inspection and modification from python code. Most of the values are automatically cast to their respective types, e.g. `nsteps` will always be an `int` and `ref-t` will always be a list of `float`. The default for unknow parameters is a list of `str` to allow for the highest felxibility possible.\n",
    "\n",
    "The class supports writing of its (possibly changed) content to a new `.mdp` file by using its `.write()` method and also knows if its content has been changed since parsing the original `.mdp` file. It even supports the (undocumented) keyformat CHARMM-GUI uses in which all `-` are replaced by `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one MDP object per engine, in principal we could use the same object but this way is more customizable,\n",
    "# e.g. we could want to modify our setup have the engines run at a different temperatures\n",
    "mdps = [aimmdd.MDP(\"gmx_infiles/md.mdp\") for _ in range(n_engines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP has been changed since parsing:  False\n",
      "Parsed content:\n",
      "---------------\n",
      "title  :  ['test']\n",
      "cpp  :  ['/lib/cpp']\n",
      "include  :  ['-I../top']\n",
      "define  :  []\n",
      "integrator  :  ['md-vv']\n",
      "dt  :  0.002\n",
      "nsteps  :  -1\n",
      "nstxout  :  10\n",
      "nstvout  :  10\n",
      "nstlog  :  10\n",
      "nstenergy  :  10\n",
      "nstxout-compressed  :  10\n",
      "compressed-x-grps  :  ['Protein', 'SOL']\n",
      "energygrps  :  ['Protein', 'SOL']\n",
      "nstlist  :  10\n",
      "ns-type  :  ['grid']\n",
      "cutoff-scheme  :  ['Verlet']\n",
      "rlist  :  1.1\n",
      "coulombtype  :  ['PME']\n",
      "rcoulomb  :  1.1\n",
      "rvdw  :  1.1\n",
      "tcoupl  :  ['Berendsen']\n",
      "tc-grps  :  ['Protein', 'SOL']\n",
      "tau-t  :  [0.1, 0.1]\n",
      "ref-t  :  [300.0, 300.0]\n",
      "Pcoupl  :  ['Berendsen']\n",
      "tau-p  :  1.0\n",
      "compressibility  :  [4.5e-05]\n",
      "ref-p  :  [1.0]\n",
      "gen-vel  :  ['no']\n",
      "gen-temp  :  300.0\n",
      "gen-seed  :  173529\n",
      "constraints  :  ['all-bonds']\n"
     ]
    }
   ],
   "source": [
    "# lets have a look at what is inside\n",
    "print(\"MDP has been changed since parsing: \", mdps[0].changed)\n",
    "print(\"Parsed content:\")\n",
    "print(\"---------------\")\n",
    "for key, val in mdps[0].items():\n",
    "    print(key, \" : \", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets set the xtc output frequency to 0 in all MDPs, we will use the trr anyways\n",
    "# we will also increase the trr output frequency by a bit and add the `continuation` parameter\n",
    "nstout = 20\n",
    "for mdp in mdps:\n",
    "    mdp['nstvout'] = nstout\n",
    "    mdp[\"nstxout\"] = nstout\n",
    "    mdp[\"nstlog\"] = nstout\n",
    "    mdp[\"nstenergy\"] = nstout\n",
    "    mdp[\"nstxout-compressed\"] = 0\n",
    "    mdp[\"continuation\"] = \"yes\"  # dont apply constraints to the initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP has been changed since parsing:  True\n",
      "Parsed content:\n",
      "---------------\n",
      "title  :  ['test']\n",
      "cpp  :  ['/lib/cpp']\n",
      "include  :  ['-I../top']\n",
      "define  :  []\n",
      "integrator  :  ['md-vv']\n",
      "dt  :  0.002\n",
      "nsteps  :  -1\n",
      "nstxout  :  20\n",
      "nstvout  :  20\n",
      "nstlog  :  20\n",
      "nstenergy  :  20\n",
      "nstxout-compressed  :  0\n",
      "compressed-x-grps  :  ['Protein', 'SOL']\n",
      "energygrps  :  ['Protein', 'SOL']\n",
      "nstlist  :  10\n",
      "ns-type  :  ['grid']\n",
      "cutoff-scheme  :  ['Verlet']\n",
      "rlist  :  1.1\n",
      "coulombtype  :  ['PME']\n",
      "rcoulomb  :  1.1\n",
      "rvdw  :  1.1\n",
      "tcoupl  :  ['Berendsen']\n",
      "tc-grps  :  ['Protein', 'SOL']\n",
      "tau-t  :  [0.1, 0.1]\n",
      "ref-t  :  [300.0, 300.0]\n",
      "Pcoupl  :  ['Berendsen']\n",
      "tau-p  :  1.0\n",
      "compressibility  :  [4.5e-05]\n",
      "ref-p  :  [1.0]\n",
      "gen-vel  :  ['no']\n",
      "gen-temp  :  300.0\n",
      "gen-seed  :  173529\n",
      "constraints  :  ['all-bonds']\n",
      "continuation  :  ['yes']\n"
     ]
    }
   ],
   "source": [
    "# have a look again\n",
    "print(\"MDP has been changed since parsing: \", mdps[0].changed)\n",
    "print(\"Parsed content:\")\n",
    "print(\"---------------\")\n",
    "for key, val in mdps[0].items():\n",
    "    print(key, \" : \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have set the molecular dynamcis parameters we can prepare a gromacs MD run.\n",
    "The gromacs engines `prepare()` method will call grompp, as with grompp you can use a specific starting configuration (the grompp `-t` option) or start the structure file (`.gro`) the engine got at initialization.\n",
    "\n",
    "### Lets prepare the first engine without a starting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = engines[0]  # get it out of the list so tab-help/completion works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prepare method is an async def function (a coroutine) and must be awaited\n",
    "await e0.prepare(starting_configuration=None, workdir=wdirs[0], deffnm=\"test\", run_config=mdps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets prepare all other engines at once with the same initial configuration\n",
    "We can use asyncio.gather to run all coroutines concurrently, for prepare this does not make a big difference (since it is fast), but the same mechanism enables us to run all 4 gromacs engines in parallel later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an aimmd.distributed.Trajectory of the initial configuration\n",
    "init_conf = aimmdd.Trajectory(trajectory_file=\"gmx_infiles/conf.trr\",\n",
    "                              structure_file=\"gmx_infiles/conf.gro\",\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and prepare the engines (the return value of prepare is None)\n",
    "await asyncio.gather(*(e.prepare(starting_configuration=init_conf, workdir=wdir, deffnm=\"test\", run_config=mdp)\n",
    "                       for e, wdir, mdp in zip(engines[1:], wdirs[1:], mdps[1:])\n",
    "                       )\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run the engines for a number of steps each.\n",
    "We will first run the last engine in the list alone and then all 4 concurrently for the same number of steps to show off the power of the concurrent execution of the gromacs subprocesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # import time to be able to show off ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one engine for 100000 integration steps took 82.9078 seconds.\n",
      "The produced trajectory (Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir3/test.part0001.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir3/test.tpr)) has a length of 5001 frames.\n",
      "This length is the number of steps divided by the engines output frequency (=20).\n",
      "Note, that we are off by plus one because the initial configuration is in the trajectory for gromacs.\n",
      "Note also that this is only true when explicitly passing nsteps to the `run` methods, unfortunately the real relation between frames\n",
      "and steps done is a bit more involved...See the docstring for `GmxEngine.steps_done` if you are brave and want to know more ;)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    }
   ],
   "source": [
    "nsteps = 100000\n",
    "\n",
    "# run one engine and time it\n",
    "start = time.time()\n",
    "# the engine will return an aimmd.distributed.Trajectory with the produced trajectory (part)\n",
    "traj = await engines[-1].run_steps(nsteps=nsteps, steps_per_part=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running one engine for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"The produced trajectory ({traj}) has a length of {len(traj)} frames.\")\n",
    "print(f\"This length is the number of steps divided by the engines output frequency (={engines[-1].nstout}).\")\n",
    "print(\"Note, that we are off by plus one because the initial configuration is in the trajectory for gromacs.\")\n",
    "print(\"Note also that this is only true when explicitly passing nsteps to the `run` methods, unfortunately the real relation between frames\")\n",
    "print(\"and steps done is a bit more involved...See the docstring for `GmxEngine.steps_done` if you are brave and want to know more ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 100000 integration steps took 84.7066 seconds.\n",
      "But now we have a list of 4 trajectories with 100000 steps each...\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir0/test.part0001.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir0/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir1/test.part0001.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir1/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir2/test.part0001.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir2/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir3/test.part0002.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir3/test.tpr)  with length: 5001\n"
     ]
    }
   ],
   "source": [
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "# Now each engine will return an aimmd.distributed.Trajectory with the produced trajectory (part)\n",
    "# i.e. trajs will be a list of trajectories (in the same order as the engines in the list)\n",
    "trajs = await asyncio.gather(*(e.run_steps(nsteps=nsteps, steps_per_part=True) for e in engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"But now we have a list of {len(trajs)} trajectories with {nsteps} steps each...\")\n",
    "for t in trajs:\n",
    "    print(t, f\" with length: {len(t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `prepare_from_files` to initialize new engines and pick up where we left off with the 'old' ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the engines\n",
    "new_engines = [aimmdd.GmxEngine(gro_file=\"gmx_infiles/conf.gro\",\n",
    "                                top_file=\"gmx_infiles/topol.top\",\n",
    "                                ndx_file=\"gmx_infiles/index.ndx\",\n",
    "                                mdrun_extra_args=\"-nt 2\",  # use this if your version of GMX is compiled with thread-MPI support\n",
    "                                #mdrun_extra_args=\"-ntomp 2\",  # use this for GMX without thread-MPI support\n",
    "                                )\n",
    "               for _ in range(n_engines)]\n",
    "e0 = new_engines[0]  # get one out for the autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and initialize with prepare_from_files\n",
    "await e0.prepare_from_files(workdir=wdirs[0], deffnm=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the others concurrent in one go\n",
    "await asyncio.gather(*(e.prepare_from_files(workdir=wdir, deffnm=\"test\") for e, wdir in zip(new_engines[1:], wdirs[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can do another round of MD in all engines in parallel\n",
    "Note that the partnums indicate that we picked up exactly where we left of. We could additionally check using the trajectories `.last_step` and `.first_step` properties, compare and observe that the last step in the previous MD runs will be the first step in these here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 100000 integration steps took 83.73851346969604 seconds.\n",
      "But now we have a list of 4 trajectories with 100000 steps each...\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir0/test.part0002.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir0/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir1/test.part0002.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir1/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir2/test.part0002.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir2/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir3/test.part0003.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir3/test.tpr)  with length: 5001\n"
     ]
    }
   ],
   "source": [
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "trajs = await asyncio.gather(*(e.run_steps(nsteps=nsteps, steps_per_part=True) for e in new_engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {nsteps} integration steps took {end - start} seconds.\")\n",
    "print(f\"But now we have a list of {len(trajs)} trajectories with {nsteps} steps each...\")\n",
    "for t in trajs:\n",
    "    print(t, f\" with length: {len(t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for specified walltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 0.01 h (=36.0 s) took 36.5816 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    }
   ],
   "source": [
    "walltime = 0.01 # 0.01 h = 36 s\n",
    "\n",
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "trajs = await asyncio.gather(*(e.run_walltime(walltime) for e in new_engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {walltime} h (={walltime*60*60} s) took {round(end - start, 4)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for specified walltime or number of steps (depending on what is reached first)\n",
    "We can also use the generic `run()` method which takes one or both of the `walltime` and `nsteps` arguments, it will finish as soon as one of the conditions is fullfilled. As the `run_steps()` method it also accepts the `steps_per_part` argument making it particularly useful to run in chunks (of length walltime) but for a fixed total number of steps.\n",
    "\n",
    "Note that we can either check if `engine.steps_done < n_steps_desired` (as we do below) or call the `engine.run(nsteps=n_steps_desired)` method until it returns `None` instead of a trajectory object, which indicates that the total number of steps done in that engine is exactly the requested number of total steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242720, 242800, 242880, 349280]\n",
      "[True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([e.steps_done for e in new_engines])\n",
    "print([e.steps_done < (max([e.steps_done for e in new_engines]) + 20000) for e in new_engines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n",
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n",
      "/home/think/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran for a total of 3 loops. It took us 106.5936 seconds.\n"
     ]
    }
   ],
   "source": [
    "walltime = 0.01 # 0.01 h = 36 s\n",
    "nsteps = max([e.steps_done for e in new_engines]) + 20000\n",
    "\n",
    "all_trajs = []\n",
    "all_times = []\n",
    "while any([e.steps_done < nsteps for e in new_engines]):\n",
    "    # run all engines at once and time it\n",
    "    start = time.time()\n",
    "    trajs = await asyncio.gather(*(e.run(walltime=walltime, nsteps=nsteps, steps_per_part=False) for e in new_engines))\n",
    "    end = time.time()\n",
    "    all_trajs.append(trajs)\n",
    "    all_times.append(end-start)\n",
    "\n",
    "print(f\"Ran for a total of {len(all_times)} loops. It took us {round(sum(all_times), 4)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir0/test.part0006.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir0/test.tpr),\n",
       " Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir1/test.part0006.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir1/test.tpr),\n",
       " Trajectory(trajectory_file=/home/think/scratch/aimmd_distributed/engine_wdir2/test.part0006.trr, structure_file=/home/think/scratch/aimmd_distributed/engine_wdir2/test.tpr),\n",
       " None]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the last engine will probably already have produced a `None` instead of a trajectory in the last iteration\n",
    "# (since it is some steps ahead of the others because we ran it alone at the beginning of the notebook)\n",
    "all_trajs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMMD nature publish (py3.7.3/June-2021)",
   "language": "python",
   "name": "aimmd_nature_publish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
