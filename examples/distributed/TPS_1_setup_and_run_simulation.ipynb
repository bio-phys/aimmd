{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massively parallel Transition Path Sampling\n",
    "\n",
    "## Notebook 1: Setup and run TPS simulation\n",
    "\n",
    "This is the first of a series of example notebooks on massively parallel transition path sampling. We will use multiple samplers (each generating its own Markov chain) that are all steered by one central reaction coordinate model. This has the benefit that the central model learns from all chains/samplers, which is more time efficient since we can run all samplers at the same time (e.g. on an HPC cluster). And since the chains will diverge from each other the central model will also see multiple reaction mechanisms at the same time and learn all of them, i.e. the training samples are more diverse. Since all chains have equal weight you can still easily calculate ensemble averages over the transition path ensemble by weighting each Monte carlo state in each chain with equal weight. Note, that to start the sampling we do need an initial transition for each sampler/Markov chain (as opposed to TPS from equilibrium points). If you use different initial transitions for each sampler this can actually be a benefit as it enables you to estimate if the ensemble is converged by comparing the chains to each other (which you will see in the analysis notebook).\n",
    "\n",
    "In this notebook we will use capped alanine dipetide as our example molecule and look at the transition between $C7_{eq}$ and $\\alpha_R$ states. We will use the locally running `GmxEngine` and `PyTrajectoryFunctionWrapper` classes (such that you can run it on your workstation), but you can easily perform a massively parallel TPS on a HPC cluster running SLURM by using the `SlurmGmxEngine` and `SlurmTrajectoryFunctionWrapper` classes instead. However, in that case you will probably want to use a larger (and more interessting) system than capped alanine dipeptide :)\n",
    "\n",
    "**This notebook should be run on a multi-core workstation preferably with a GPU**, otherwise you will have a very long coffee break and a very hot laptop.\n",
    "\n",
    "**Required knowledge/recommended reading:** This notebooks assumes some familarity with the `asyncmd` (namely the [gromacs] engine and TrajectoryFunctionWrapper classes). Please see the example notebooks in `asyncmd` for an introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_distributed_devel/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n",
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import MDAnalysis as mda\n",
    "# asyncmd for the engine and Trajectory class\n",
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx\n",
    "from asyncmd import Trajectory\n",
    "# aimmd for the TPS\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd\n",
    "# and pytorch for the reaction coordinate model\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "\n",
    "scratch_dir = \"/homeloc/scratch/aimmd_distributed/\"\n",
    "#scratch_dir = \".\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"TransitionPathSampling_ala\")\n",
    "\n",
    "if not os.path.isdir(workdir):\n",
    "    os.mkdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logging to a file (optional)\n",
    "\n",
    "The next few cells are just to show you how to configure pythons logging module to write to a logfile in the directory where we do the simulation. It is not necessary to run aimmd but it might be helpful to find out what went wrong if something does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# executing this file sets the variable LOGCONFIG, which is a dictionary of logging presets \n",
    "%run ../resources/logconf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 'WARN', 'handlers': ['stdf', 'warnout']}\n",
      "{'level': 'INFO'}\n",
      "{'class': 'logging.FileHandler', 'level': 'INFO', 'mode': 'w', 'filename': 'simulation.log', 'formatter': 'standardFormatter'}\n"
     ]
    }
   ],
   "source": [
    "# have a look at the default logging level (the level used for the root logger)\n",
    "print(LOGCONFIG[\"loggers\"][\"\"])\n",
    "# have a look at the logger for aimmd\n",
    "print(LOGCONFIG[\"loggers\"][\"aimmd\"])\n",
    "# and have a look at the log-level for the filehandler\n",
    "print(LOGCONFIG[\"handlers\"][\"stdf\"])\n",
    "# the last two should both be `INFO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: more logging to file\n",
    "level = \"INFO\"\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"level\"] = level\n",
    "LOGCONFIG[\"loggers\"][\"aimmd\"][\"level\"] = level\n",
    "LOGCONFIG[\"loggers\"][\"asyncmd\"] = {\"level\": level}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can either modify single values or use it as is to get the same setup as in the OPS default logging config file\n",
    "# you could e.g. do LOGCONF['handlers']['stdf']['filename'] = new_name to change the filename of the log\n",
    "# the default is to create 'simulation.log' and 'initialization.log' in the current working directory\n",
    "import logging.config\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"filename\"] = os.path.join(workdir, \"simulation_pathsampling.log\")\n",
    "LOGCONFIG[\"handlers\"][\"initf\"][\"filename\"] = os.path.join(workdir, \"initlog_pathsampling.log\")\n",
    "logging.config.dictConfig(LOGCONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the TPS simulation\n",
    "\n",
    "To setup the TPS we need the following:\n",
    " - Decide how many Markov chain samplers we want to run in parallel\n",
    " - Create a storage file to save our models, trainset and other simulation results\n",
    " - Define the metastable states to know when to stop the integration (and what defines a transition)\n",
    " - Define the underlying dynamics (through defining a gromacs engine with its options)\n",
    " - Load our initial transitions, here we will use the three transitions that are part of the repository. Generating initial transitions can be facilitated in a multitude of ways (high temperature/pressure/etc, pulling, steered MD, ...) and can/should take into account previous knowledge of the system. For an example on how to generate initial transitions if you have access (or can generate) configurations close to a putative transition state see the CommittorSimulation notebook.\n",
    " - Define the reaction coordinate model and the space it is learning in by choosing the `descriptor_transform` (which transforms from configurations to descriptor space)\n",
    " - Define the sampling scheme, i.e. how we generate new trials (here we will use two way shooting moves with random velocities).\n",
    " - Create a trainset into which we will add the simulation results (shooting outcomes).\n",
    " - Define the `Task`s to run after a specified number of trials. These are used to e.g. train the reaction coordinate model or save the trainset, model and brain at specified intervals. They are similar to the openpathsampling concept of hooks.\n",
    " - Set the initial transitions for each Markov chain sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samplers = 5  # results in 2*n_samplers gmx engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create storage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = aimmd.Storage(os.path.join(workdir, \"storage.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State definition\n",
    "\n",
    "`alpha_R` and `C7_eq` are python functions (using MDAnalysis) to claculate for each frame of a trajctory if it belongs to the respective state or not (returning an array of `True` and `False` values). We wrapp them using `asyncmd`s TrajectoryFunctionWrapper to make them awaitable and run in parallel where possible (e.g. when the code releases the GIL or when you use the SlurmTrajectoryFunctionWrapper to submit the calculation via SLURM).\n",
    "\n",
    "If you want to learn more about the TrajectoryFunctionWrappers have a look at the example notebooks and documentation ofa `asyncmd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state functions\n",
    "from state_funcs_mda import alpha_R, C7_eq\n",
    "\n",
    "wrapped_alphaR = asyncmd.trajectory.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "wrapped_C7_eq = asyncmd.trajectory.PyTrajectoryFunctionWrapper(C7_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underlying dynamics\n",
    "\n",
    "We will use the localy running GmxEngine from `asyncmd` (again have a look at the examples and documentation there to learn more), you could however easily run the TPS on a HPC cluster by using the SlurmGmxEngine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine(s) for the PathMovers\n",
    "# (they will all be the same)\n",
    "gro = \"gmx_infiles/conf.gro\"\n",
    "top = \"gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"gmx_infiles/index.ndx\"\n",
    "mdp = asyncgmx.MDP(\"gmx_infiles/md.mdp\")\n",
    "\n",
    "gmx_engine_kwargs = {\"mdconfig\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"output_traj_type\": \"XTC\",\n",
    "                     #\"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     \"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = asyncgmx.GmxEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load initial transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial transitions\n",
    "tp_lb = Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_files=\"gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr\")\n",
    "tp_short = Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_files=\"gmx_infiles/TP_short_low_barrier_300K_amber99sbildn.trr\")\n",
    "tp_short2 = Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_files=\"gmx_infiles/TP_short2_low_barrier_300K_amber99sbildn.trr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reaction coordinate model and `descriptor_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import descriptor_transform for the model\n",
    "# descriptor_func_ic gives us an internal coordinate representation (i.e. bond lengths, angles and dihedrals)\n",
    "# descriptor_func_psi_phi gives us the ψ and φ dihedral angles (we use it to project to a 2d space in which we can look at the TPE)\n",
    "from state_funcs_mda import descriptor_func_ic, descriptor_func_psi_phi\n",
    "\n",
    "# and as usual wrapp them to become awaitable\n",
    "wrapped_transform = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_ic, call_kwargs={\"molecule_selection\": \"protein\"})\n",
    "wrapped_psi_phi = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_psi_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the descriptors for them to infer the number of inputs for our model\n",
    "# we would only need one but since we can execute them in parallel anyway...\n",
    "descriptors_for_tp, descriptors_for_tp_short, descriptors_for_tp_short2  = await asyncio.gather(wrapped_transform(tp_lb),\n",
    "                                                                                                wrapped_transform(tp_short),\n",
    "                                                                                                wrapped_transform(tp_short2),\n",
    "                                                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit 1 is 66 units wide.\n",
      "Dropout before it is 0.18674307214231128.\n",
      "ResUnit 2 is 41 units wide.\n",
      "Dropout before it is 0.1162432499771616.\n",
      "ResUnit 3 is 25 units wide.\n",
      "Dropout before it is 0.07235873872180604.\n",
      "ResUnit 4 is 16 units wide.\n",
      "Dropout before it is 0.045041643884176266.\n",
      "ResUnit 5 is 10 units wide.\n",
      "Dropout before it is 0.02803738317757008.\n"
     ]
    }
   ],
   "source": [
    "# model architecture definition\n",
    "# we use a pyramidal ResNet as described in \"Machine-guided path sampling to discover mechanisms of molecular self-organization\" (Nat.Comput.Sci 2023)\n",
    "\n",
    "n_lay_pyramid = 5  # number of resunits\n",
    "n_unit_top = 10  # number of units in the last layer before the log_predictor\n",
    "dropout_base = 0.3  # dropot fraction in the first layer (will be reduced going to the top)\n",
    "n_unit_base = cv_ndim = descriptors_for_tp.shape[1]  # input dimension\n",
    "# the factor by which we reduce the number of units per layer (the width) and the dropout fraction\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "# create a list of modules to build our pytorch reaction coodrinate model from\n",
    "modules = []\n",
    "\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    modules += [aimmd.pytorch.networks.FFNet(n_in=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                             n_hidden=[max(n_unit_top, int(n_unit_base * fact**i))],  # 1 hidden layer network\n",
    "                                             activation=torch.nn.Identity(),\n",
    "                                             dropout={\"0\": dropout_base * fact**i}\n",
    "                                             )\n",
    "                ]\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i)))} units wide.\")\n",
    "    print(f\"Dropout before it is {dropout_base * fact**i}.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\n",
    "                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\n",
    "                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\n",
    "                                                 modules=modules,  # modules is a list of initialized torch.nn.Modules from arcd.pytorch.networks\n",
    "                                                 )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "\n",
    "# choose and initialize an optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapp the pytorch neural network model in a RCModel class,\n",
    "# these classes know how to decide if they should train in a self-consistent way\n",
    "# and they also know how to transform from configurations to descriptors space (because they know about the descriptor_transform) \n",
    "# Here we take an ExpectedEfficiencyPytorchRCModel,\n",
    "# this RCmodel scales the learning rate by the expected efficiency factor (1 - n_TP_true / n_TP_expected)**2\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,  \n",
    "                                                            'lr_min': 5e-5,  # lr_min = lr_0 / 20 is a good choice empirically\n",
    "                                                            'epochs_per_train': 3,\n",
    "                                                            'window': 100,\n",
    "                                                            'batch_size': 8192,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_transform,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the sampling scheme\n",
    "\n",
    "We will first define the shooting point selection, the shooting point selector (or equivalently the choosen selection scheme) determines the acceptance probability for each new trial because it decides on how we select the new shooting points from the last accepted transition.\n",
    "\n",
    "We will then use the selector to setup our sampling scheme, which is very simple here as it only consists of one mover (the two way shooting mover). However you can use an arbitray number of movers (potentially defining a probability for each of them), in that case each mover will be picked with the given probability to generate the next trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the reaction coodrinate model to select SPs biased towards its current guess of the transition state\n",
    "# from the last accepted transition\n",
    "# the RCModelSelectorFromTraj has a couple of options to customize its behavior (e.g. to decide how sharply peaked the selection should be)\n",
    "# but we will leave it at its default parmeters for now\n",
    "# One notable feature is the debsity adaption, which will correct for the denisty of points on transition projected into the space of the committor,\n",
    "# it is enabled by default\n",
    "spselector = aimmdd.spselectors.RCModelSPSelectorFromTraj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a list of movers\n",
    "# since we want to create n_sampler identical samplers it is easiest to use the `Brain.samplers_from_moverlist()` function\n",
    "# This function will create n_sampler identical PathChainSamplers where the movers for each sampler are\n",
    "# specified by movers_cls (a list of mover classes) and movers_kwargs (a dict with keyword arguments used for initialization of the movers)\n",
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  # NOTE: choose this as short as possible!\n",
    "                  #       since ala is super-small and commits fast we should make sure\n",
    "                  #       that most trials reach a state in the first part\n",
    "                  #       this in turn makes sure that we do not call gromasc multiple times per trial (saving setup time)\n",
    "                  #       but still ensures that the resulting trajectories are not too long and large\n",
    "                  #       it also reduces the time needed per step (we need at least walltime_per_part hours per step)\n",
    "                  #'walltime_per_part': 0.000015625,  # 0.055125 s per part\n",
    "                  'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  #'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  #'walltime_per_part': 0.000125,  # 0.45 s per part\n",
    "                  #'walltime_per_part': 0.001,  # 3.6 s per part\n",
    "                  #'walltime_per_part': 0.004,  # 14.4 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": spselector,  # use the spselctor we have defined above \n",
    "                  \"max_steps\": 500 * 10**5,  # 500 steps * dt (2 fs) = 1 ps\n",
    "                  }\n",
    "                 ]\n",
    "\n",
    "# Note that for full flexibility of the sampling scheme setup we could also use a list of lists with initialized movers\n",
    "# then however we need the outermost list to be of length n_sampler as shown below\n",
    "#movers = [[aimmdd.TwoWayShootingPathMover(states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "#                                          engine_cls=gmx_engine_cls,\n",
    "#                                          engine_kwargs=gmx_engine_kwargs,\n",
    "#                                          engine_config=mdp,\n",
    "#                                          walltime_per_part=0.00003125,\n",
    "#                                          T=mdp[\"ref-t\"][0],\n",
    "#                                          sp_selector=spselector,\n",
    "#                                          max_steps=500 * 10**5,\n",
    "#                                         )\n",
    "#           ] for i in range(n_samplers)\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain tasks\n",
    "\n",
    "Each task will be run after `interval` finished trials by the brain, you can also define your own tasks to modify the behaviour of the TPS simulation easily (openpathsampling users should think of hooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    # the TrainingTask takes care of training the model (or better: reminding the model to decide if it wants to train)\n",
    "    aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "    # the SaveTask saves the model, trainset and brain to storage at specified interval (default=100 steps) during the simulation\n",
    "    aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset),\n",
    "    # the DensityCollectionTask takes care of updating the estimate of the density of shooting points\n",
    "    # projected into committor space\n",
    "    # It needs to know what the ensemble is we shoot from (e.g. \"custom\" for a self-defined set of shooting points\n",
    "    #  or the default \"p_x_TP\" if we shoot from previous transitions)\n",
    "    aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                              first_collection=100,\n",
    "                                              recreate_interval=250,\n",
    "                                              interval=10\n",
    "                                              ),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the 'easy' way to setup n_sampler identical samplers (using `samplers_from_moverlist` as described above)\n",
    "brain = aimmdd.Brain.samplers_from_moverlist(model=model, workdir=workdir, storage=storage,\n",
    "                                             n_sampler=n_samplers,\n",
    "                                             movers_cls=movers_cls, movers_kwargs=movers_kwargs,\n",
    "                                             samplers_use_same_stepcollection=False,\n",
    "                                             tasks=tasks)\n",
    "                                             # Note that we left mover_weights=None at its default, this results\n",
    "                                             # in uniform weights for all movers\n",
    "\n",
    "\n",
    "# and this would be the full __init__ call to the brain (given you defined `movers` as above commented out) \n",
    "# it gives you full flexibility of setting up every PathChainSamplers individually\n",
    "#brain = aimmdd.Brain(model=model, workdir=workdir, storage=storage, movers=movers, mover_weights=[[1.], [1.], [1.]], tasks=tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed initial transitions for each Markov chain\n",
    "\n",
    "Here we will use a convinience function of the brain that takes a list of transitions (and optionaly a list of weights) and seeds all Markov chains from the given transitions (and weights) randomly. If no weights are given a uniform distribution is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed initial transitions\n",
    "brain.seed_initial_paths(trajectories=[tp_lb, tp_short, tp_short2], weights=[1., 1., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the TPS simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 10000 cummulative MCSteps took 13457.09845161438 s (= 224.284974193573 min).\n"
     ]
    }
   ],
   "source": [
    "n_steps = 10000\n",
    "start = time.time()\n",
    "\n",
    "await brain.run_for_n_steps(n_steps)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Running for {n_steps} cummulative MCSteps took {end-start} s (= {(end-start)/60} min).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the last model, trainset and brain to storage\n",
    "This enables us to do the analysis in a different notebook and/or continue the TPS simulation from the last step easily.\n",
    "\n",
    "Note that the `SaveTask` defined above also saves the reaction coordinate model, the trainset and the brain, but only at the specified interval, so it is always good to save the last state. For simulations where single steps are already quite costly it might be worth sacrificing some disk space at setting the `interval=1` to save after every finished step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the last model\n",
    "storage.rcmodels[\"model_to_continue_with\"] = model\n",
    "storage.save_trainset(trainset)  # the trainset\n",
    "storage.save_brain(brain)  # and the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the storage to make sure all writes are synced\n",
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimmd distributed devel (py3.9 with asyncmd)",
   "language": "python",
   "name": "aimmd_distributed_devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
